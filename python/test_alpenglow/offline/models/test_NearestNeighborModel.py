import alpenglow as prs
from alpenglow.offline.models import NearestNeighborModel
from alpenglow.offline.evaluation import NdcgScore
import alpenglow.Getter as rs
import pandas as pd
import numpy as np
import unittest
import sys
import pytest
import alpenglow.cpp
compiler = alpenglow.cpp.__compiler
stdlib = alpenglow.cpp.__stdlib


class TestNearestNeighborModel(unittest.TestCase):
    def test_rmse(self):
        data = pd.read_csv(
            "python/test_alpenglow/test_data_4",
            sep=' ',
            header=None,
            names=['time', 'user', 'item', 'id', 'score', 'eval']
        )
        model = NearestNeighborModel()
        model.fit(data)

        def predict(model, user, item):
            rd = rs.RecDat()
            rd.user = user
            rd.item = item
            return model.prediction(rd)

        errors = [(1 - predict(model.model, u, i))**2 for (u, i) in data[['user', 'item']].values]
        rmse = np.sqrt(pd.Series(errors)).mean()
        assert rmse == pytest.approx(53.651, abs=0.5)

    def test_ranking(self):
        data = pd.read_csv(
            "python/test_alpenglow/test_data_4",
            sep=' ',
            header=None,
            names=['time', 'user', 'item', 'id', 'score', 'eval']
        )
        exp = NearestNeighborModel()
        exp.fit(data)
        preds = exp.recommend(exclude_known=False, k=20)

        if(compiler == "gcc" and stdlib == "libstdc++"):
            assert preds['item'].tolist() ==  \
                [94, 166, 225, 30, 300, 455, 299, 337, 250, 338, 468, 128, 4, 442, 204, 462, 168, 293, 260, 452, 94, 166, 30, 225, 442, 98, 300, 372, 337, 299, 462, 455, 256, 196, 338, 247, 128, 177, 102, 62, 94, 166, 225, 30, 98, 300, 442, 299, 372, 337, 462, 455, 250, 496, 196, 429, 338, 427, 256, 371, 30, 166, 94, 225, 300, 372, 299, 337, 462, 196, 468, 128, 4, 442, 204, 260, 455, 293, 452, 98, 30, 300, 166, 442, 225, 94, 462, 204, 299, 250, 468, 128, 4, 372, 455, 260, 168, 293, 452, 98, 166, 30, 94, 225, 300, 442, 462, 372, 98, 299, 196, 337, 128, 165, 455, 383, 204, 247, 86, 256, 30, 94, 166, 225, 442, 300, 196, 462, 299, 204, 98, 455, 372, 256, 337, 250, 86, 128, 4, 468, 225, 94, 166, 442, 300, 337, 455, 372, 98, 299, 30, 4, 468, 128, 204, 260, 462, 293, 452, 383, 166, 94, 225, 30, 300, 299, 98, 442, 337, 372, 455, 62, 196, 462, 250, 215, 40, 338, 496, 86, 94, 166, 30, 225, 442, 372, 462, 337, 338, 98, 300, 256, 299, 455, 120, 128, 247, 4, 468, 204, 94, 225, 166, 30, 442, 299, 455, 98, 337, 300, 372, 462, 196, 338, 4, 468, 128, 204, 260, 293, 30, 94, 225, 166, 300, 442, 299, 462, 196, 337, 372, 98, 250, 455, 256, 204, 40, 400, 165, 4, 94, 166, 30, 225, 300, 299, 442, 372, 98, 337, 462, 455, 196, 62, 204, 40, 250, 4, 128, 468, 94, 166, 225, 30, 442, 300, 98, 299, 372, 462, 337, 196, 455, 429, 371, 250, 296, 122, 256, 409, 94, 30, 166, 442, 225, 98, 196, 462, 455, 299, 468, 128, 4, 204, 372, 260, 168, 293, 452, 383, 225, 94, 299, 166, 442, 337, 300, 455, 372, 98, 468, 128, 4, 204, 462, 168, 293, 452, 260, 383, 94, 225, 30, 166, 300, 98, 442, 299, 462, 455, 372, 247, 337, 196, 256, 128, 338, 102, 250, 86, 94, 300, 30, 166, 225, 299, 455, 250, 442, 337, 462, 204, 196, 338, 98, 86, 247, 4, 128, 468, 94, 30, 166, 225, 300, 299, 98, 442, 337, 372, 455, 462, 196, 62, 250, 215, 204, 338, 496, 40, 94, 30, 225, 166, 300, 299, 98, 442, 337, 372, 455, 462, 250, 62, 338, 371, 429, 427, 4, 468, 94, 225, 166, 30, 300, 98, 442, 299, 337, 372, 196, 455, 462, 250, 496, 40, 204, 156, 62, 429, 225, 166, 300, 299, 94, 30, 442, 98, 372, 337, 462, 455, 196, 86, 204, 128, 427, 496, 215, 4, 94, 225, 166, 30, 442, 300, 299, 98, 462, 372, 337, 196, 455, 204, 250, 62, 496, 215, 256, 247, 94, 166, 225, 30, 98, 442, 300, 299, 372, 337, 462, 338, 455, 256, 250, 120, 496, 40, 427, 429, 94, 30, 166, 225, 442, 300, 299, 372, 337, 98, 455, 62, 462, 196, 128, 247, 338, 40, 86, 204, 94, 166, 225, 30, 442, 300, 299, 372, 98, 462, 337, 455, 256, 247, 429, 102, 196, 427, 36, 128, 94, 166, 30, 225, 442, 98, 196, 462, 455, 299, 128, 372, 300, 256, 247, 4, 468, 204, 260, 168, 94, 225, 30, 166, 442, 300, 372, 337, 299, 98, 462, 455, 196, 338, 247, 165, 383, 128, 62, 293, 225, 94, 166, 442, 300, 337, 455, 372, 98, 299, 30, 4, 468, 128, 204, 260, 462, 293, 452, 383, 94, 30, 166, 442, 225, 98, 196, 462, 455, 299, 468, 128, 4, 204, 372, 260, 168, 293, 452, 383, 94, 30, 166, 225, 299, 462, 196, 442, 300, 98, 372, 337, 455, 40, 250, 4, 468, 128, 204, 260, 166, 30, 98, 225, 300, 94, 442, 299, 337, 372, 455, 462, 247, 196, 256, 86, 204, 128, 177, 102, 94, 30, 299, 166, 98, 442, 225, 62, 300, 372, 337, 40, 196, 496, 250, 215, 4, 468, 128, 204, 30, 94, 225, 166, 300, 299, 98, 442, 337, 372, 462, 455, 250, 62, 338, 196, 496, 371, 429, 4, 94, 300, 225, 166, 30, 299, 98, 442, 455, 372, 337, 462, 196, 204, 250, 86, 247, 108, 156, 450, 166, 94, 30, 225, 442, 299, 372, 337, 300, 98, 462, 455, 62, 196, 338, 120, 256, 496, 4, 468, 94, 30, 166, 225, 442, 98, 300, 337, 299, 372, 462, 455, 196, 338, 256, 62, 250, 156, 215, 120, 94, 166, 30, 225, 300, 98, 442, 455, 299, 196, 462, 372, 337, 204, 250, 256, 247, 156, 86, 128, 94, 166, 30, 225, 300, 442, 299, 98, 372, 462, 337, 455, 196, 496, 250, 429, 427, 338, 36, 215, 94, 166, 30, 225, 299, 455, 442, 300, 196, 98, 462, 337, 250, 338, 4, 468, 128, 204, 260, 168, 225, 166, 30, 94, 299, 442, 98, 372, 300, 337, 462, 455, 196, 120, 256, 4, 468, 128, 204, 260, 94, 30, 299, 166, 442, 98, 300, 372, 337, 62, 225, 40, 196, 4, 468, 128, 204, 455, 260, 462, 225, 94, 299, 166, 442, 337, 300, 455, 372, 98, 468, 128, 4, 204, 462, 168, 293, 452, 260, 383, 94, 30, 166, 225, 442, 299, 300, 98, 337, 372, 462, 196, 496, 455, 250, 338, 62, 40, 215, 256, 94, 30, 225, 166, 442, 299, 98, 300, 372, 337, 462, 496, 40, 338, 62, 455, 256, 215, 36, 120, 94, 30, 225, 442, 299, 98, 300, 462, 372, 337, 468, 128, 4, 166, 204, 260, 455, 293, 452, 383, 94, 30, 166, 225, 300, 442, 98, 299, 372, 462, 337, 196, 455, 204, 250, 256, 156, 38, 86, 338, 94, 30, 225, 166, 300, 98, 442, 299, 372, 462, 337, 455, 196, 496, 250, 256, 62, 215, 247, 204, 166, 30, 300, 94, 442, 225, 372, 196, 256, 337, 468, 128, 4, 204, 455, 260, 462, 293, 452, 98, 94, 225, 30, 166, 442, 300, 299, 372, 462, 337, 98, 455, 196, 256, 204, 36, 250, 496, 338, 4, 94, 30, 225, 166, 442, 300, 372, 299, 98, 337, 462, 455, 62, 429, 196, 247, 338, 496, 165, 371, 30, 225, 94, 166, 442, 372, 98, 337, 300, 455, 120, 256, 4, 468, 128, 204, 260, 293, 452, 383, 299, 442, 94, 225, 30, 166, 300, 98, 337, 372, 462, 455, 62, 4, 468, 128, 204, 260, 293, 452, 94, 166, 30, 225, 300, 98, 442, 372, 299, 337, 462, 455, 256, 247, 204, 338, 196, 128, 86, 102, 94, 30, 166, 225, 300, 442, 462, 299, 372, 98, 337, 196, 455, 204, 256, 86, 62, 165, 496, 128, 94, 166, 30, 225, 442, 98, 299, 300, 372, 337, 462, 338, 455, 496, 250, 256, 196, 40, 36, 120, 30, 300, 166, 442, 225, 94, 462, 204, 299, 250, 468, 128, 4, 372, 455, 260, 168, 293, 452, 98, 225, 94, 299, 166, 442, 337, 300, 455, 372, 98, 468, 128, 4, 204, 462, 168, 293, 452, 260, 383, 30, 166, 98, 300, 94, 225, 442, 372, 299, 337, 462, 62, 455, 427, 496, 4, 468, 128, 204, 260, 94, 166, 225, 30, 300, 455, 299, 337, 250, 338, 468, 128, 4, 442, 204, 462, 168, 293, 260, 452, 30, 94, 225, 300, 98, 166, 299, 442, 372, 337, 462, 455, 128, 102, 256, 427, 496, 4, 468, 204, 225, 30, 300, 299, 94, 337, 166, 442, 98, 372, 462, 455, 250, 338, 4, 468, 128, 204, 260, 293, 94, 30, 225, 442, 299, 98, 300, 462, 372, 337, 468, 128, 4, 166, 204, 260, 455, 293, 452, 383, 94, 30, 225, 166, 300, 442, 299, 98, 372, 337, 455, 462, 196, 204, 62, 250, 86, 247, 168, 256, 94, 30, 166, 225, 442, 299, 98, 300, 337, 372, 462, 455, 196, 250, 496, 338, 62, 40, 215, 156]

        assert NdcgScore(data, preds, top_k=20) == pytest.approx(0.49225361293335407, abs=5*1e-3)

        preds2 = exp.recommend(users = [1, 2], exclude_known=False)
        assert preds2['user'].unique().tolist() == [1,2]

        preds = exp.recommend(exclude_known=True)
        joined_preds = preds.join(
            data.set_index(['user', 'item']),
            on=['user','item'], how='inner'
        )
        assert len(joined_preds) == 0
